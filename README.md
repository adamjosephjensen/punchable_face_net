# Punchable Face Net - Image Labeler

This tool provides a web interface to label images based on a subjective "punchability" criterion using a 4-point scale. It's designed to work with the CelebA dataset and includes features like timed labeling, skipping, flagging, and undo.

## Prerequisites

*   **Python 3:** Ensure Python 3 is installed.
*   **Flask:** The web application framework. Install using pip:
    ```bash
    pip install Flask
    ```
*   **CelebA Dataset:** You need the CelebA dataset downloaded and accessible on your system. Specifically:
    *   The attribute file: `list_attr_celeba.txt`
    *   The image directory: `img_align_celeba`
*   **Configuration:** Before running any scripts, verify the hardcoded paths within the Python files match your system:
    *   `generate_training_list.py`: Check `CELEBA_ATTRIBUTE_FILE`.
    *   `app/labeler.py`: Check `CELEBA_IMAGE_DIR`.

## Setup & Usage

### 1. Generate the Training Image List

This step selects a subset of images based on specific attributes (currently configured for "Male" = "1") and creates a list file used by the labeler.

*   **Script:** `generate_training_list.py`
*   **Configuration:**
    *   `CELEBA_ATTRIBUTE_FILE`: Path to your `list_attr_celeba.txt`.
    *   `OUTPUT_FILE`: `./data/training_imgs.txt` (where the list will be saved).
    *   `TARGET_ATTRIBUTE`: The CelebA attribute to filter by (e.g., "Male").
    *   `TARGET_VALUE`: The value for the target attribute (e.g., "1").
    *   `DEFAULT_NUM_IMAGES`: Default number of images to select.
*   **Run:** Execute the script from the project root directory. You can optionally specify the number of images:
    ```bash
    # Generate list with default number of images (1000)
    python generate_training_list.py

    # Generate list with a specific number of images (e.g., 500)
    python generate_training_list.py --num_images 500
    ```
*   **Output:** This creates `./data/training_imgs.txt` containing the filenames.

### 2. Run the Labeler Application

This starts a local web server to display images and record your labels.

*   **Script:** `app/labeler.py`
*   **Configuration:**
    *   `CELEBA_IMAGE_DIR`: Path to your CelebA `img_align_celeba` directory.
    *   `TRAINING_LIST_FILE`: Path to the generated list (`./data/training_imgs.txt`).
    *   `LABELS_FILE`: Path where labels will be saved (`./data/labels.csv`).
*   **Run:** Execute the script from the project root directory:
    ```bash
    python app/labeler.py
    ```
*   **Access:** Open your web browser and go to `http://127.0.0.1:5000` (or the address shown in the terminal, possibly using your machine's IP if accessing from another device on the network).
*   **Labeling:**
    *   **Timer:** You have **1.5 seconds** to label each image after it appears. If the timer expires, the image is automatically skipped. This encourages capturing a quick, visceral reaction rather than prolonged judgment.
    *   **Buttons:** Click one of the four label buttons ("VERY punchable", "Punchable", "NOT punchable", "VERY NOT punchable"), "Skip", or "Flag".
    *   **Keyboard Shortcuts:**
        *   <kbd>H</kbd>: VERY punchable
        *   <kbd>J</kbd>: Punchable
        *   <kbd>K</kbd>: NOT punchable
        *   <kbd>L</kbd>: VERY NOT punchable
        *   <kbd>S</kbd>: Skip (Manually skip the current image)
        *   <kbd>F</kbd>: Flag (Mark image as problematic, e.g., wrong type, corrupted)
        *   <kbd>A</kbd>: Undo (Revert the last action - label, skip, or flag)
    *   Labels, skips, and flags are saved immediately. Flagged images are excluded from future labeling and training. Skipped images (manual or timed) are shown again only after all other unseen images have been processed.

## Output Files

*   **`./data/training_imgs.txt`:** List of image filenames selected for labeling. Generated by `generate_training_list.py`.
*   **`./data/labels.csv`:** Stores the successful labels. Each row contains a `filename` and its corresponding numerical `label` (3: VERY punchable, 2: Punchable, 1: NOT punchable, 0: VERY NOT punchable). Created/updated by `app/labeler.py`.
*   **`./data/skipped.txt`:** List of filenames that were skipped (either manually or via the timer). Created/updated by `app/labeler.py`.
*   **`./data/flagged.txt`:** List of filenames that were flagged as problematic. Created/updated by `app/labeler.py`.

## Training a Model

This project includes scripts to train a simple image classifier using transfer learning to predict
the "annoying" label based on the collected data.

### 1. Prepare Data Splits

First, ensure you have generated the `data/labels.csv` file using the Flask labeler (containing only successfully labeled, non-flagged images). Then, split this data into training, validation (dev), and test sets:

```bash
python split_data.py
```

This will create `data/train.csv`, `data/dev.csv`, and `data/test.csv`. Skipped and flagged images are automatically excluded as they are not present in `labels.csv`.

2. Run Training

The train.py script handles the model training process. It uses a pre-trained ResNet18 model and
fine-tunes only the final classification layer on your labeled data.

To start training with default settings (10 epochs, batch size 32, learning rate 0.001, using the
default CelebA image path):


python train.py


You can customize the training using command-line arguments:

 • --image_dir: Path to the CelebA image directory (if different from the default).
 • --csv_train, --csv_val: Paths to the training/validation CSV files.
 • --epochs: Number of training epochs.
 • --batch_size: Training batch size.
 • --lr: Learning rate for the optimizer.
 • --log_dir: Directory to save TensorBoard logs.
 • --checkpoint_dir: Directory to save the best model weights.
 • --num_workers: Number of CPU workers for loading data.

Example with custom epochs and learning rate:


python train.py --epochs 20 --lr 0.0005


The script will print progress for each epoch and save the model weights (best_model.pth)
corresponding to the highest validation accuracy achieved during training into the checkpoints/
directory.

3. Monitor with TensorBoard

While the training script is running, you can monitor the learning curves (loss and accuracy for
training and validation sets) using TensorBoard.

Open a separate terminal, navigate to your project directory, and run:


tensorboard --logdir runs


(Assuming the default --log_dir was used. If you specified a different directory, use that path
instead).

TensorBoard will provide a URL (usually http://localhost:6006/). Open this URL in your web browser
to view the training progress.

About the Initial Model (ResNet18 Transfer Learning)

 • Why ResNet18? ResNet (Residual Network) architectures are well-established and effective for
   image classification. ResNet18 is a relatively small and fast version, making it a good starting
   point for quick baseline experiments.
 • Transfer Learning: Instead of training a model from scratch (which would require vast amounts of
   data), we use a ResNet18 model pre-trained on the large ImageNet dataset. This model already
   understands general visual features (edges, textures, shapes, etc.).
 • What is Trained? We freeze the weights of all the pre-trained layers (the convolutional base) and
   only train the final classification layer (a fully connected layer, `model.fc` in the code). This
   layer is replaced with a new one tailored to our specific task (**4 outputs**: corresponding to the "punchability" scale from 0 to 3). This process adapts the general visual knowledge of the pre-trained model to our specific subjective labels with relatively little data.

